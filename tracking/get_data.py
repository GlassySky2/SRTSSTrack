from track_combine_test1 import *


class DynamicDatasetCollector:
    def __init__(self, project_name="UAV_Training_Data", padding_factor=2.5, min_size=128):
        self.root = project_name
        self.padding_factor = padding_factor
        self.min_size = min_size
        self.img_dir = os.path.join(self.root, "images")
        self.lbl_dir = os.path.join(self.root, "labels")
        os.makedirs(self.img_dir, exist_ok=True)
        os.makedirs(self.lbl_dir, exist_ok=True)
        self.counter = 0

    def collect_frame(self, frame, tracks, frame_id, target_ids, neg_ids=None, video_prefix="vid"):
        fh, fw = frame.shape[:2]
        neg_ids = neg_ids or []  # é»˜è®¤ä¸ºç©ºåˆ—è¡¨

        for t in tracks:
            # åªæœ‰å½“è¿½è¸ª ID åœ¨ã€æ­£æ ·æœ¬åˆ—è¡¨ã€‘æˆ–ã€è´Ÿæ ·æœ¬åˆ—è¡¨ã€‘ä¸­ï¼Œä¸”å½“å‰å¸§ç›®æ ‡æœªä¸¢å¤±æ—¶æ‰æ”¶é›†
            combined_all_ids = target_ids + neg_ids
            if t.track_id in combined_all_ids and t.misses <= 10:
                # --- ä»¥ä¸‹æ‰€æœ‰é€»è¾‘ä¸ä½ åŸå§‹ä»£ç å®Œå…¨ä¸€è‡´ ---
                tx, ty, tw, th = t.box
                cx_raw, cy_raw = tx + tw / 2.0, ty + th / 2.0

                side = max(tw, th) * self.padding_factor
                crop_size = int(np.ceil(side / 32) * 32)
                crop_size = max(crop_size, self.min_size)

                nx1 = int(max(0, min(fw - crop_size, cx_raw - crop_size / 2.0)))
                ny1 = int(max(0, min(fh - crop_size, cy_raw - crop_size / 2.0)))

                crop_img = frame[ny1:ny1 + crop_size, nx1:nx1 + crop_size]

                # æ–‡ä»¶åè§„åˆ™ (å¦‚æœæ˜¯è´Ÿæ ·æœ¬ï¼ŒåŠ ä¸Š _neg æ ‡è¯†æ–¹ä¾¿ä½ ä»¥åè‚‰çœ¼åŒºåˆ†)
                suffix = "_neg" if t.track_id in neg_ids else ""
                file_base = f"{video_prefix}_f{frame_id:06d}_id{t.track_id}{suffix}_{self.counter}"

                # ä¿å­˜å›¾ç‰‡
                cv2.imwrite(os.path.join(self.img_dir, f"{file_base}.jpg"), crop_img)

                # --- ä¿®æ”¹å†™æ ‡ç­¾çš„é€»è¾‘ ---
                lbl_path = os.path.join(self.lbl_dir, f"{file_base}.txt")
                with open(lbl_path, 'w') as f:
                    if t.track_id in neg_ids:
                        # å¦‚æœæ˜¯è´Ÿæ ·æœ¬ï¼Œä¿æŒæ–‡ä»¶ä¸ºç©º (YOLO è¦æ±‚çš„èƒŒæ™¯æ ·æœ¬æ ¼å¼)
                        f.write("")
                    else:
                        # æ­£æ ·æœ¬é€»è¾‘ä¿æŒå®Œå…¨ä¸å˜
                        new_cx = (cx_raw - nx1) / crop_size
                        new_cy = (cy_raw - ny1) / crop_size
                        new_bw = tw / crop_size
                        new_bh = th / crop_size
                        f.write(f"0 {new_cx:.6f} {new_cy:.6f} {new_bw:.6f} {new_bh:.6f}\n")

                self.counter += 1


def run_system(video_path, collection_tasks=None, sutrack_cfg="sutrack_b224"):
    """
        æé€Ÿé‡‡é›†ç‰ˆï¼šé’ˆå¯¹å¤šè§†é¢‘é˜²é‡åå’Œç¨³å®šæ€§è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–
        """
    # 0. è‡ªåŠ¨æå–è§†é¢‘æ–‡ä»¶åä½œä¸ºå‰ç¼€
    video_abs_path = os.path.abspath(video_path)
    video_name_prefix = os.path.splitext(os.path.basename(video_abs_path))[0]

    # 1. åˆå§‹åŒ–
    collector = DynamicDatasetCollector(project_name="UAV_Training_Data")
    sut_params = parameters(sutrack_cfg)
    sut_params.debug = 0  # æé€Ÿ

    start_time = time.time()
    # å¼ºåˆ¶ä½¿ç”¨ FFMPEG æ’ä»¶ï¼Œé¿å…è·¯å¾„æ•°å­—å¼•èµ· OpenCV è¯¯åˆ¤
    cap = cv2.VideoCapture(video_abs_path, cv2.CAP_FFMPEG)

    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_abs_path}")
        return

    fw, fh = int(cap.get(3)), int(cap.get(4))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    tracker = TrackManager(sutrack_params=sut_params)

    prev_gray = None
    prev_sky_line_f = None
    frame_count = 0
    pts_ref = None

    cfg = {
        'CLUSTER_DIST': 30,
        'ALPHA': 0.3,
        'W_MOTION': 1.5,
        'W_AREA': 1.2,
        'W_SPATIAL': 1.5,
        'MOTION_FLOOR': 1.0,
        'BUFFER_PIXELS': 0,
    }

    print(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_name_prefix} | é¢„è®¡: {total_frames} å¸§")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        frame_count += 1
        # æ¯ä¸€å¸§å¼€å§‹æ—¶ï¼Œåˆå§‹åŒ–è°ƒè¯•ç”»å¸ƒ
        canvas = frame.copy()

        # 1. å¤©é™…çº¿å¹³æ»‘
        raw_sky_line = get_sky_line(frame)
        if prev_sky_line_f is None:
            sky_line_f = raw_sky_line.astype(np.float32)
        else:
            sky_line_f = cfg['ALPHA'] * raw_sky_line + (1 - cfg['ALPHA']) * prev_sky_line_f
        prev_sky_line_f = sky_line_f.copy()
        sky_line = sky_line_f.astype(np.int32)

        # 2. å‡†å¤‡é®ç½©
        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # ä¸º SUTrack å‡†å¤‡ RGB å›¾
        global_mask = np.ones((fh, fw), dtype=np.uint8) * 255
        # å»ºè®®ï¼šåªåœ¨å¤©é™…çº¿ä»¥ä¸‹ï¼ˆåœ°é¢åŒºåŸŸï¼‰æ‰¾èƒŒæ™¯å‚è€ƒç‚¹ï¼Œè¿™æ · M çŸ©é˜µæ›´ç¨³
        for c in range(fw):
            global_mask[0:sky_line[c], c] = 0

        row_idx = np.arange(fh).reshape(-1, 1)
        sky_mask = (row_idx < sky_line).astype(np.uint8) * 255

        validated_with_score = []
        m_status = "LOST"

        # 3. è¿åŠ¨è¡¥å¿ä¸æ£€æµ‹
        if prev_gray is not None and prev_gray.shape == curr_gray.shape:
            M = None
            # --- ç‰¹å¾ç‚¹å¤ç”¨é€»è¾‘å¼€å§‹ ---
            # å¦‚æœæ²¡æœ‰ç‚¹ï¼Œæˆ–è€…å­˜æ´»çš„ç‚¹å¤ªå°‘ï¼ˆå°‘äº 40 ä¸ªï¼‰ï¼Œé‡æ–°æ£€æµ‹ç‰¹å¾ç‚¹
            if pts_ref is None or len(pts_ref) < 40:
                pts_ref = cv2.goodFeaturesToTrack(prev_gray, 120, 0.01, 10, mask=global_mask)
            if pts_ref is not None:
                # å…‰æµè¿½è¸ªä¸Šä¸€å¸§çš„ç‚¹åˆ°è¿™ä¸€å¸§
                pts_curr, st, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, pts_ref, None, **LK_PARAMS)

                # ç­›é€‰è¿½è¸ªæˆåŠŸçš„ç‚¹
                good_prev = pts_ref[st == 1]
                good_curr = pts_curr[st == 1]

                if len(good_prev) >= 10:  # è‡³å°‘ 10 ä¸ªç‚¹æ‰è®¡ç®—ä»¿å°„å˜æ¢
                    M, _ = cv2.estimateAffinePartial2D(good_prev, good_curr)
                    # ã€æ ¸å¿ƒä¼˜åŒ–ã€‘å°†å½“å‰å¸§æˆåŠŸçš„ç‚¹å­˜ä¸‹æ¥ï¼Œä½œä¸ºä¸‹ä¸€å¸§çš„å‚è€ƒç‚¹
                    # è¿™æ ·ä¸‹ä¸€å¸§å¾ªç¯æ—¶ï¼Œå°±ä¸éœ€è¦è·‘ goodFeaturesToTrack äº†
                    pts_ref = good_curr.reshape(-1, 1, 2)
                else:
                    pts_ref = None  # ç‚¹å¤ªå°‘ï¼Œä¸‹ä¸€å¸§å¼ºåˆ¶åˆ·æ–°
            # --- ç‰¹å¾ç‚¹å¤ç”¨é€»è¾‘ç»“æŸ ---

            if M is not None:
                m_status = "LOCKED"
                # ============ ã€ç‰©ç†è£å‰ªä¿®æ”¹å¼€å§‹ã€‘ ============
                # A. è®¡ç®—è£å‰ªè¾¹ç•Œï¼šæ‰¾åˆ°å¤©é™…çº¿æœ€æ·±çš„ç‚¹ï¼Œå¢åŠ  åƒç´ ç¼“å†²åŒº
                y_cutoff = int(np.max(sky_line)+2)
                y_cutoff = min(fh, y_cutoff)  # é˜²æ­¢è¶Šç•Œ

                # B. å®æ–½ç‰©ç†è£å‰ª (ç”Ÿæˆæ–°çš„æ›´å°çš„å†…å­˜çŸ©é˜µ)
                # åªæœ‰è¿™é‡Œåˆ‡äº†ï¼Œåé¢çš„ cvtColor, CLAHE, Blackhat æ‰ä¼šæé€Ÿ
                roi_frame = frame[0:y_cutoff, :]
                roi_sky_mask = sky_mask[0:y_cutoff, :]
                # C. è°ƒç”¨æ£€æµ‹å‡½æ•°ï¼šä¼ å…¥è£å‰ªåçš„å›¾
                # æ­¤æ—¶ detect_on_crop å†…éƒ¨å¤„ç†çš„åƒç´ ç‚¹å¤§å¹…å‡å°‘
                # cands = detect_on_crop(roi_frame, roi_sky_mask, offset_x=0, offset_y=0)
                # ============ ã€ç‰©ç†è£å‰ªä¿®æ”¹ç»“æŸã€‘ ============
                # æš´åŠ›æå–åŸå§‹ç¢ç‚¹ (æ­¤æ—¶ detect_on_crop åªç®¡æŠ“ç‚¹ï¼Œä¸ç®¡åˆ†æ•°)
                raw_cands = detect_on_crop(roi_frame, roi_sky_mask, offset_x=0, offset_y=0)
                # print("raw_cands",len(raw_cands))
                # # --- B. è°ƒè¯•ç¬¬ä¸€å±‚ï¼šåŸå§‹ç¢ç‚¹ (Blue) ---
                # raw_cands = detect_on_crop(roi_frame, roi_sky_mask, offset_x=0, offset_y=0)
                # for cand in raw_cands:
                #     x, y, w, h = cand['box']
                #     cv2.rectangle(canvas, (x, y), (x + w, y + h), (255, 0, 0), 1)

                # ã€æ ¸å¿ƒé‡æ„ï¼šå…ˆèšç±»ã€‘

                # ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰å†™çš„é«˜æ•ˆç‰ˆèšç±»ï¼Œå°†ç¢ç‚¹åˆæˆä¸ºç–‘ä¼¼ç›®æ ‡
                clustered_cands = cluster_detections_initial(raw_cands, cluster_dist=20)

                # # --- C. è°ƒè¯•ç¬¬äºŒå±‚ï¼šç‰©ç†èšç±» (Yellow) ---
                # # å…ˆèšç±»ï¼Œå‡å°‘åç»­å…‰æµéªŒè¯çš„æ¬¡æ•°
                # clustered_cands = cluster_detections_initial(raw_cands, cluster_dist=20)
                # for cand in clustered_cands:
                #     x, y, w, h = cand['box']
                #     cv2.rectangle(canvas, (x, y), (x + w, y + h), (0, 255, 255), 2)
                #     cv2.putText(canvas, f"f:{cand.get('fragments', 1)}", (x, y - 5),
                #                 cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
                if len(clustered_cands) > 0:
                    # --- å‘é‡åŒ–ä¼˜åŒ–å¼€å§‹ ---
                    # 1. æ•´ç†æ‰€æœ‰å¾…æ£€æµ‹ç‚¹çš„ä¸­å¿ƒåæ ‡ (N, 1, 2)
                    pts_list = []
                    for cand in clustered_cands:
                        x, y, w, h = cand['box']
                        pts_list.append([x + w / 2, y + h / 2])
                    p0 = np.array(pts_list, dtype=np.float32).reshape(-1, 1, 2)

                    # 2. æ‰¹é‡è®¡ç®—å…‰æµ
                    p1, st_obj, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None, **LK_PARAMS)

                    # 3. æ‰¹é‡è®¡ç®—èƒŒæ™¯é¢„æœŸåæ ‡
                    expected_pts = cv2.transform(p0, M)

                    # 4. è·å–æ‰€æœ‰è¿½è¸ªå™¨çš„é¢„æµ‹ä½ç½®ç”¨äºè®¡ç®—ç©ºé—´å¥–åŠ± (æå‰è®¡ç®—)
                    track_preds = [t.get_predict() for t in tracker.tracks] if tracker.tracks else []

                    # 5. éå†å¤„ç†ç»“æœ
                    for i, cand in enumerate(clustered_cands):
                        if st_obj[i] == 1:
                            cx, cy = pts_list[i]
                            # ç‰©ç†è¾¹ç•Œå¿«é€Ÿè¿‡æ»¤
                            idx_x = max(0, min(fw - 1, int(cx)))
                            if cy > (sky_line[idx_x] + cfg['BUFFER_PIXELS']): continue
                            # è®¡ç®—å‡€è¿åŠ¨åˆ†æ•° (å‘é‡åŒ–ç»“æœ)
                            net_motion = np.linalg.norm(p1[i][0] - expected_pts[i][0])

                            # è®¡ç®—ç©ºé—´å¥–åŠ±
                            spatial_bonus = 0
                            is_near_track = False
                            if track_preds:
                                # è®¡ç®—å½“å‰ç‚¹åˆ°æ‰€æœ‰è¿½è¸ªå™¨é¢„æµ‹ç‚¹çš„è·ç¦»
                                dists = np.sqrt(np.sum((np.array([cx, cy]) - np.array(track_preds)) ** 2, axis=1))
                                min_dist = np.min(dists)
                                if min_dist < 40:
                                    is_near_track = True
                                    spatial_bonus = cfg['W_SPATIAL'] * max(0, (40 - min_dist) / 8.0)
                            # å‡†å…¥é€»è¾‘
                            if (net_motion > cfg['MOTION_FLOOR'] or is_near_track) and (net_motion < 40.0):
                                eff_motion = max(net_motion, 1.0 if is_near_track else 0)
                                motion_part = cfg['W_MOTION'] * eff_motion
                                # å…³é”®ï¼šä½¿ç”¨èšç±»åçš„æ€»é¢ç§¯è¿›è¡Œé¢ç§¯åŠ åˆ†
                                area_val = cand['area']
                                area_part = cfg['W_AREA'] * np.log1p(area_val + 1)
                                # # é¢å¤–åŠ åˆ†é¡¹ï¼šç”±å¤šä¸ªç¢ç‰‡èšæˆçš„ç›®æ ‡ç½®ä¿¡åº¦æ›´é«˜
                                # fragment_bonus = 0.5 if cand.get('fragment_count', 1) > 1 else 0
                                score = motion_part + area_part + spatial_bonus
                                if score > 2.0:
                                    cand['score'] = max(0.01, score)
                                    validated_with_score.append(cand)

        # 4. èšç±»ä¸è¿½è¸ª
        final_detections = cluster_scored_detections(validated_with_score, cluster_dist=cfg['CLUSTER_DIST'])
        # # --- 4. è°ƒè¯•ç¬¬ä¸‰å±‚ï¼šæœ€ç»ˆèšåˆä¸è¯„åˆ†ç»“æœ (Green) ---
        # final_detections = cluster_scored_detections(validated_with_score, cluster_dist=cfg['CLUSTER_DIST'])
        # for cand in final_detections:
        #     x, y, w, h = cand['box']
        #     s = cand['score']
        #     cv2.rectangle(canvas, (x, y), (x + w, y + h), (0, 255, 0), 2)
        #     cv2.putText(canvas, f"S:{s:.1f}", (x, y + h + 15),
        #                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        # # --- 5. æ˜¾ç¤ºä¸ä¿å­˜ ---
        # if canvas is not None:
        #     # ç¼©å°ç”»é¢å¯ä»¥æå¤§åœ°æé«˜è¿œç¨‹ä¼ è¾“æˆåŠŸç‡ï¼Œé˜²æ­¢é»‘å±
        #     display_size = (960, 540)
        #     debug_small = cv2.resize(canvas, display_size)
        #
        #     cv2.imshow("Debug Board", debug_small)
        #
        #     # è¿œç¨‹ç¯å¢ƒä¸‹ waitKey(1) æœ‰æ—¶å¤ªå¿«ï¼Œå°è¯•åŠ å¤§åˆ° 30 (çº¦ 30ms)
        #     # å¦‚æœæŒ‰ä¸‹ 'q' é”®åˆ™é€€å‡º
        #     key = cv2.waitKey(1000) & 0xFF
        #     if key == ord('q'):
        #         break
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨å¤šçº¿ç¨‹ update ---

        tracker.update(final_detections, frame_rgb)

        # D. æ ¸å¿ƒé‡‡é›†é€»è¾‘
        if collection_tasks:
            pos_ids = []
            neg_ids = []
            for task in collection_tasks:
                if task["range"][0] <= frame_count <= task["range"][1]:
                    # åˆ†åˆ«æ”¶é›†æ­£è´Ÿ ID
                    pos_ids.extend(task.get("ids", []))
                    neg_ids.extend(task.get("neg_ids", []))

            if pos_ids or neg_ids:
                collector.collect_frame(
                    frame,
                    tracker.tracks,
                    frame_count,
                    target_ids=list(set(pos_ids)),
                    neg_ids=list(set(neg_ids)),
                    video_prefix=video_name_prefix
                )

        # E. è¿›åº¦åé¦ˆ
        if frame_count % 100 == 0:
            elapsed = time.time() - start_time
            print(
                f"è¿›åº¦: {frame_count}/{total_frames} | é€Ÿåº¦: {frame_count / elapsed:.1f} FPS | æ”¶é›†æ•°: {collector.counter}")

        prev_gray = curr_gray.copy()

    cap.release()
    print(f"âœ… é‡‡é›†å®Œæˆï¼æ•°æ®ä¿å­˜åœ¨: {os.path.abspath(collector.root)}")

if __name__ == "__main__":
    run_system(
        video_path='./test_videos/2026.1.08/DJI_20260110144928_0011_W.MP4',
        collection_tasks=[
            # æ­£å¸¸é‡‡é›† ID 1 (æ­£æ ·æœ¬)
            {"range": (145, 195), "ids": [3]},
            {"range": (242, 335), "ids": [3]},
            {"range": (421, 779), "ids": [3]},

            # {"range": (790, 828), "ids": [3]},
            # {"range": (1763, 2073), "ids": [3]},
            # {"range": (2821, 3034), "ids": [1,2,3,4]},

            # åŒæ—¶é‡‡é›† ID 2 (æ­£æ ·æœ¬) å’Œ ID 5 (æ¯”å¦‚æ˜¯è¯¯æŠ¥çš„å¹²æ‰°ç‰©ï¼Œè®¾ä¸ºè´Ÿæ ·æœ¬)
            # {"range": (1302, 1355), "ids": [2], "neg_ids": [1,4]},
            # {"range": (1376, 1902), "ids": [2], "neg_ids": [1,3,4]},

            # è¿™ä¸€æ®µåªè¦ ID 3 çš„è´Ÿæ ·æœ¬
            {"range": (387, 400), "neg_ids": [3]},
            # {"range": (2380, 4878), "neg_ids": [1,2,3,4,5]},
            # {"range": (1225, 2700), "neg_ids": [2]},
            # {"range": (307, 1041), "neg_ids": [2,3]},
        ]
    )
